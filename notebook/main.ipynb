{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT 기반 한국어 감성 분석\n",
    "\n",
    "## 1. bert-base-multilingual-cased\n",
    "    * transformers 의 Bert tokenzier, Bert for sequence classification\n",
    "    * 도서 \"딥 러닝을 통한 자연어 처리 입문\" 참고\n",
    "\n",
    "## 2. KoBERT\n",
    "    * SKTBrain 팀이 개발한 Bert 모델 기반 한국어 성능 향상\n",
    "    * Model 내부 및 예측 흐름 확인\n",
    "    \n",
    "## 3. Conclusion\n",
    "    * 임의의 input 문장이 들어왔을 때 긍정/부정 판별\n",
    "    * 두 개의 모델 Accuracy 비교\n",
    "    * 학습 내용 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "# for data analyze and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import urllib.request\n",
    "from tqdm import tqdm, notebook\n",
    "\n",
    "\n",
    "# machine learning\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gluonnlp as nlp\n",
    "\n",
    "\n",
    "# kobert\n",
    "from kobert_tokenizer import KoBERTTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of train data: 150000\n",
      "numbers of test data: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            document  label\n",
       "0                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
    "\n",
    "train = pd.read_table(\"ratings_train.txt\", usecols = ['document','label'])\n",
    "test = pd.read_table(\"ratings_test.txt\", usecols = ['document','label'])\n",
    "\n",
    "print(f'numbers of train data: {len(train)}')\n",
    "print(f'numbers of test data: {len(test)}')\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-4a98031647ec>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['document'] = train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "<ipython-input-3-4a98031647ec>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['document'] = train['document'].str.replace('^ +', \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokeinzed text : ['[CLS]', '아', '더', '##빙', '진', '##짜', '짜', '##증', '##나', '##네', '##요', '목', '##소', '##리', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# train data preprocessing\n",
    "# CLS : classifier\n",
    "# SEP : separator\n",
    "train['document'] = train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train['document'] = train['document'].str.replace('^ +', \"\")\n",
    "train['document'].replace('', np.nan, inplace=True)\n",
    "train = train.dropna(how = 'any')\n",
    "\n",
    "# before tokenizing\n",
    "document_bert = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train['document']]\n",
    "\n",
    "# tokenizing\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(s) for s in document_bert]\n",
    "print(f\"tokeinzed text : {tokenized_texts[0]}\")\n",
    "\n",
    "# padding\n",
    "MAX_LEN = max([len(s) for s in tokenized_texts]) + 1\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')\n",
    "\n",
    "# attention mask\n",
    "attention_masks = []\n",
    "\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "# split train and validation set   \n",
    "train_inputs, validation_inputs, train_labels, validation_labels = \\\n",
    "    train_test_split(input_ids, train['label'].values, random_state=42, test_size=0.1)\n",
    "\n",
    "# attention mask for train and validation set\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=42, \n",
    "                                                       test_size=0.1)\n",
    "\n",
    "# convert to tensor\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# data loader\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "                        train_data, # which is converted to a TensorDataset\n",
    "                        sampler=train_sampler, # reason of no shuffle is that we need to use validation set\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        pin_memory=True, # GPU memory\n",
    "                        num_workers=4, # for parallel processing\n",
    "                        )\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "                        validation_data,\n",
    "                        sampler=validation_sampler, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=4,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-df121774fae7>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['document'] = test['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "<ipython-input-4-df121774fae7>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['document'] = test['document'].str.replace('^ +', \"\")\n"
     ]
    }
   ],
   "source": [
    "# test data preprocessing\n",
    "\n",
    "test['document'] = test['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test['document'] = test['document'].str.replace('^ +', \"\")\n",
    "test['document'].replace('', np.nan, inplace=True)\n",
    "test = test.dropna(how = 'any')\n",
    "\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in test['document']]\n",
    "labels = test['label'].values\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(\n",
    "                    test_data, # which is converted to a TensorDataset\n",
    "                    sampler=test_sampler, # reason of no shuffle is that we need to use validation set\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    pin_memory=True, # GPU memory\n",
    "                    num_workers=4, # for parallel processing\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU check (cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM3-32GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. bert-base-multilingual-cased\n",
    "\n",
    "    * transformers 의 Bert tokenzier, Bert for sequence classification\n",
    "    * 도서 \"딥 러닝을 통한 자연어 처리 입문\" 참고했고, 커스터마이징을 진행했습니다.\n",
    "    * 코드 내부적으로 흐름을 파악하기 위해 Arguments를 바꿔가며 실험했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# loss function and optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # Learning rate\n",
    "                  eps = 1e-8 # Epsilon for AdamW to avoid numerical issues (zero division)\n",
    "                )\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 5\n",
    "\n",
    "# loss function to calculate loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# total number of training step \n",
    "# len(train_dataloader) : number of batches\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "warmup_ratio = 0.1\n",
    "warmup_step = int(total_steps * warmup_ratio)\n",
    "\n",
    "# scheduler to decrease learning rate\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_step,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# time format\n",
    "def format_time(elapsed):\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # change to hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_bert_multilingual_cased_per_epoch = []\n",
    "validation_accuracy_bert_multilingual_cased_per_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch   500  of  4,184.    Elapsed: 0:01:47.\n",
      "  Batch 1,000  of  4,184.    Elapsed: 0:03:33.\n",
      "  Batch 1,500  of  4,184.    Elapsed: 0:05:19.\n",
      "  Batch 2,000  of  4,184.    Elapsed: 0:07:04.\n",
      "  Batch 2,500  of  4,184.    Elapsed: 0:08:50.\n",
      "  Batch 3,000  of  4,184.    Elapsed: 0:10:36.\n",
      "  Batch 3,500  of  4,184.    Elapsed: 0:12:21.\n",
      "  Batch 4,000  of  4,184.    Elapsed: 0:14:07.\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:14:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:30\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch   500  of  4,184.    Elapsed: 0:01:46.\n",
      "  Batch 1,000  of  4,184.    Elapsed: 0:03:32.\n",
      "  Batch 1,500  of  4,184.    Elapsed: 0:05:18.\n",
      "  Batch 2,000  of  4,184.    Elapsed: 0:07:04.\n",
      "  Batch 2,500  of  4,184.    Elapsed: 0:08:49.\n",
      "  Batch 3,000  of  4,184.    Elapsed: 0:10:35.\n",
      "  Batch 3,500  of  4,184.    Elapsed: 0:12:21.\n",
      "  Batch 4,000  of  4,184.    Elapsed: 0:14:07.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:14:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:30\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch   500  of  4,184.    Elapsed: 0:01:46.\n",
      "  Batch 1,000  of  4,184.    Elapsed: 0:03:32.\n",
      "  Batch 1,500  of  4,184.    Elapsed: 0:05:18.\n",
      "  Batch 2,000  of  4,184.    Elapsed: 0:07:04.\n",
      "  Batch 2,500  of  4,184.    Elapsed: 0:08:49.\n",
      "  Batch 3,000  of  4,184.    Elapsed: 0:10:35.\n",
      "  Batch 3,500  of  4,184.    Elapsed: 0:12:21.\n",
      "  Batch 4,000  of  4,184.    Elapsed: 0:14:07.\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:14:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:00:30\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch   500  of  4,184.    Elapsed: 0:01:46.\n",
      "  Batch 1,000  of  4,184.    Elapsed: 0:03:32.\n",
      "  Batch 1,500  of  4,184.    Elapsed: 0:05:18.\n",
      "  Batch 2,000  of  4,184.    Elapsed: 0:07:04.\n",
      "  Batch 2,500  of  4,184.    Elapsed: 0:08:49.\n",
      "  Batch 3,000  of  4,184.    Elapsed: 0:10:35.\n",
      "  Batch 3,500  of  4,184.    Elapsed: 0:12:21.\n",
      "  Batch 4,000  of  4,184.    Elapsed: 0:14:07.\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:14:45\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:30\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch   500  of  4,184.    Elapsed: 0:01:46.\n",
      "  Batch 1,000  of  4,184.    Elapsed: 0:03:32.\n",
      "  Batch 1,500  of  4,184.    Elapsed: 0:05:18.\n",
      "  Batch 2,000  of  4,184.    Elapsed: 0:07:03.\n",
      "  Batch 2,500  of  4,184.    Elapsed: 0:08:49.\n",
      "  Batch 3,000  of  4,184.    Elapsed: 0:10:35.\n",
      "  Batch 3,500  of  4,184.    Elapsed: 0:12:21.\n",
      "  Batch 4,000  of  4,184.    Elapsed: 0:14:07.\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:14:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:30\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# zero gradients\n",
    "model.zero_grad()\n",
    "\n",
    "# loop over epochs\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # set time recorder\n",
    "    t0 = time.time()\n",
    "\n",
    "    # intialize the loss\n",
    "    total_loss = 0\n",
    "\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "        \n",
    "    # get step and batch from train_dataloader\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # progress bar\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # unpack the inputs from dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward pass                \n",
    "        # **batch\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # get loss\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # get the total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass, gradient calculation\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient clipping to avoid gradient exploding\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update weight parameters from backpropagation\n",
    "        optimizer.step()\n",
    "\n",
    "        # learning rate decay by scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # zero gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "    # evaluate the average loss over the epoch\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    train_loss_bert_multilingual_cased_per_epoch.append(avg_train_loss)\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    # set time recorder\n",
    "    t0 = time.time()\n",
    "\n",
    "    # set model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # initialize the loss and accuracy\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # get batch from val_dataloader\n",
    "    for batch in validation_dataloader:\n",
    "        # batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # unpack the inputs from dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # no need to calculate gradients because of eval mode, so set requires_grad to False\n",
    "        with torch.no_grad():     \n",
    "            # Forward pass\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # get loss\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # loss to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # calculate evaluation accuracy\n",
    "        # flat_accuracy : calculate accuracy of each batch\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    validation_accuracy_bert_multilingual_cased_per_epoch.append(eval_accuracy/nb_eval_steps)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  1,550.    Elapsed: 0:00:07.\n",
      "  Batch   200  of  1,550.    Elapsed: 0:00:13.\n",
      "  Batch   300  of  1,550.    Elapsed: 0:00:19.\n",
      "  Batch   400  of  1,550.    Elapsed: 0:00:26.\n",
      "  Batch   500  of  1,550.    Elapsed: 0:00:32.\n",
      "  Batch   600  of  1,550.    Elapsed: 0:00:38.\n",
      "  Batch   700  of  1,550.    Elapsed: 0:00:45.\n",
      "  Batch   800  of  1,550.    Elapsed: 0:00:51.\n",
      "  Batch   900  of  1,550.    Elapsed: 0:00:57.\n",
      "  Batch 1,000  of  1,550.    Elapsed: 0:01:04.\n",
      "  Batch 1,100  of  1,550.    Elapsed: 0:01:10.\n",
      "  Batch 1,200  of  1,550.    Elapsed: 0:01:16.\n",
      "  Batch 1,300  of  1,550.    Elapsed: 0:01:23.\n",
      "  Batch 1,400  of  1,550.    Elapsed: 0:01:29.\n",
      "  Batch 1,500  of  1,550.    Elapsed: 0:01:36.\n",
      "\n",
      "Accuracy: 0.86\n",
      "Test took: 0:01:39\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():     \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
    "bert_base_multilingual_cased_accuracy = eval_accuracy/nb_eval_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KoBERT\n",
    "\n",
    "```\n",
    "predefined_args = {\n",
    "        'attention_cell': 'multi_head',\n",
    "        'num_layers': 12,\n",
    "        'units': 768,\n",
    "        'hidden_size': 3072,\n",
    "        'max_length': 512,\n",
    "        'num_heads': 12,\n",
    "        'scaled': True,\n",
    "        'dropout': 0.1,\n",
    "        'use_residual': True,\n",
    "        'embed_size': 768,\n",
    "        'embed_dropout': 0.1,\n",
    "        'token_type_vocab_size': 2,\n",
    "        'word_embed': None,\n",
    "    }\n",
    "```\n",
    "\n",
    "    * SKTBrain github에 제공된 notebook을 토대로 커스터마이징을 진행했습니다.\n",
    "    * Model 내부 및 예측 흐름 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, vocab=vocab, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tokenizer.tokenize\n",
    "\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, vocab, 64, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, vocab, 64, True, False)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "                    data_train, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    num_workers=4,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True\n",
    "                    )\n",
    "test_dataloader = DataLoader(\n",
    "                    data_test, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    num_workers=4,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "    \n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # Learning rate\n",
    "                  eps = 1e-8 # Epsilon for AdamW to avoid numerical issues (zero division)\n",
    "                )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * epochs\n",
    "warmup_step = int(t_total * 0.1)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_kobert_per_epoch = []\n",
    "train_accuracy_kobert_per_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d37c4c1c8346cd9cbce510da2cc95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.6896642446517944 train acc 0.53125\n",
      "epoch 1 batch id 201 loss 0.7195993661880493 train acc 0.505752487562189\n",
      "epoch 1 batch id 401 loss 0.6234786510467529 train acc 0.5455112219451371\n",
      "epoch 1 batch id 601 loss 0.5720820426940918 train acc 0.6271318635607321\n",
      "epoch 1 batch id 801 loss 0.3160232603549957 train acc 0.6730649188514357\n",
      "epoch 1 batch id 1001 loss 0.10534768551588058 train acc 0.7058566433566433\n",
      "epoch 1 batch id 1201 loss 0.267437607049942 train acc 0.7297304329725229\n",
      "epoch 1 batch id 1401 loss 0.30100053548812866 train acc 0.746743397573162\n",
      "epoch 1 batch id 1601 loss 0.3154330551624298 train acc 0.7599742348532167\n",
      "epoch 1 batch id 1801 loss 0.412508100271225 train acc 0.7697112715158245\n",
      "epoch 1 batch id 2001 loss 0.302864670753479 train acc 0.7779079210394803\n",
      "epoch 1 batch id 2201 loss 0.2663799524307251 train acc 0.7854668332576101\n",
      "epoch 1 batch id 2401 loss 0.4452560245990753 train acc 0.7913759891711787\n",
      "epoch 1 batch id 2601 loss 0.4079663157463074 train acc 0.7970852556708958\n",
      "epoch 1 batch id 2801 loss 0.22786469757556915 train acc 0.8015887183148875\n",
      "epoch 1 batch id 3001 loss 0.16224011778831482 train acc 0.8054086137954015\n",
      "epoch 1 batch id 3201 loss 0.45652925968170166 train acc 0.8090928616057482\n",
      "epoch 1 batch id 3401 loss 0.4697261154651642 train acc 0.8122151573066745\n",
      "epoch 1 batch id 3601 loss 0.3090633749961853 train acc 0.8154158567064704\n",
      "epoch 1 batch id 3801 loss 0.2023317664861679 train acc 0.8182139568534597\n",
      "epoch 1 batch id 4001 loss 0.45421892404556274 train acc 0.8210447388152962\n",
      "epoch 1 batch id 4201 loss 0.3515925705432892 train acc 0.8235985479647703\n",
      "epoch 1 batch id 4401 loss 0.347139447927475 train acc 0.8260551579186548\n",
      "epoch 1 batch id 4601 loss 0.24945245683193207 train acc 0.8282914040425995\n",
      "epoch 1 train acc 0.8289715763651877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f913c5d150e4274ab6eca2e3775ca06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.8821377159309021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a01637dbe54bd4ab4f264f4b565a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.21942779421806335 train acc 0.9375\n",
      "epoch 2 batch id 201 loss 0.16053864359855652 train acc 0.900497512437811\n",
      "epoch 2 batch id 401 loss 0.3911174535751343 train acc 0.9011845386533666\n",
      "epoch 2 batch id 601 loss 0.35175397992134094 train acc 0.8999584026622296\n",
      "epoch 2 batch id 801 loss 0.28481703996658325 train acc 0.8999687890137328\n",
      "epoch 2 batch id 1001 loss 0.16768449544906616 train acc 0.9002872127872128\n",
      "epoch 2 batch id 1201 loss 0.1901545226573944 train acc 0.9003955037468776\n",
      "epoch 2 batch id 1401 loss 0.23256605863571167 train acc 0.9000267665952891\n",
      "epoch 2 batch id 1601 loss 0.3452270030975342 train acc 0.8995354465958776\n",
      "epoch 2 batch id 1801 loss 0.4288899898529053 train acc 0.8993441143808995\n",
      "epoch 2 batch id 2001 loss 0.17774713039398193 train acc 0.8987849825087456\n",
      "epoch 2 batch id 2201 loss 0.18110235035419464 train acc 0.8986398228078146\n",
      "epoch 2 batch id 2401 loss 0.24248681962490082 train acc 0.898362661391087\n",
      "epoch 2 batch id 2601 loss 0.07240406423807144 train acc 0.8982482698961938\n",
      "epoch 2 batch id 2801 loss 0.21673627197742462 train acc 0.898060960371296\n",
      "epoch 2 batch id 3001 loss 0.2544710636138916 train acc 0.8982214261912695\n",
      "epoch 2 batch id 3201 loss 0.28616219758987427 train acc 0.8985766166822868\n",
      "epoch 2 batch id 3401 loss 0.5311079025268555 train acc 0.8992851367244928\n",
      "epoch 2 batch id 3601 loss 0.3471547067165375 train acc 0.8993508747570119\n",
      "epoch 2 batch id 3801 loss 0.16091138124465942 train acc 0.899689226519337\n",
      "epoch 2 batch id 4001 loss 0.13370868563652039 train acc 0.8999156460884778\n",
      "epoch 2 batch id 4201 loss 0.2339814156293869 train acc 0.9002469650083313\n",
      "epoch 2 batch id 4401 loss 0.1814076006412506 train acc 0.9000511247443763\n",
      "epoch 2 batch id 4601 loss 0.3322475850582123 train acc 0.9003613344925017\n",
      "epoch 2 train acc 0.900390625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1105641e91374c8ba4ce97205258f91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.8859365003198977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5d590336094dec854ecad722945013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.22292691469192505 train acc 0.90625\n",
      "epoch 3 batch id 201 loss 0.1691727191209793 train acc 0.9353233830845771\n",
      "epoch 3 batch id 401 loss 0.10388654470443726 train acc 0.9339931421446384\n",
      "epoch 3 batch id 601 loss 0.1604059934616089 train acc 0.9337562396006656\n",
      "epoch 3 batch id 801 loss 0.3961453139781952 train acc 0.9325452559300874\n",
      "epoch 3 batch id 1001 loss 0.13517558574676514 train acc 0.9330669330669331\n",
      "epoch 3 batch id 1201 loss 0.34183600544929504 train acc 0.933544962531224\n",
      "epoch 3 batch id 1401 loss 0.1607390195131302 train acc 0.9331727337615988\n",
      "epoch 3 batch id 1601 loss 0.26959913969039917 train acc 0.9328739850093691\n",
      "epoch 3 batch id 1801 loss 0.24328456819057465 train acc 0.9331100777345919\n",
      "epoch 3 batch id 2001 loss 0.11234334856271744 train acc 0.9340798350824587\n",
      "epoch 3 batch id 2201 loss 0.07256606966257095 train acc 0.9343764198091776\n",
      "epoch 3 batch id 2401 loss 0.1881340742111206 train acc 0.9346886713869221\n",
      "epoch 3 batch id 2601 loss 0.051276665180921555 train acc 0.9345924644367551\n",
      "epoch 3 batch id 2801 loss 0.12479984760284424 train acc 0.9345992502677615\n",
      "epoch 3 batch id 3001 loss 0.0846443921327591 train acc 0.9349071142952349\n",
      "epoch 3 batch id 3201 loss 0.13510283827781677 train acc 0.9353034208059982\n",
      "epoch 3 batch id 3401 loss 0.07692041993141174 train acc 0.9351569391355483\n",
      "epoch 3 batch id 3601 loss 0.14486676454544067 train acc 0.9352783948903083\n",
      "epoch 3 batch id 3801 loss 0.0729750320315361 train acc 0.9353624046303605\n",
      "epoch 3 batch id 4001 loss 0.11272435635328293 train acc 0.9351802674331418\n",
      "epoch 3 batch id 4201 loss 0.24420039355754852 train acc 0.9352832658890741\n",
      "epoch 3 batch id 4401 loss 0.16790452599525452 train acc 0.9353698023176551\n",
      "epoch 3 batch id 4601 loss 0.22184206545352936 train acc 0.9357204955444468\n",
      "epoch 3 train acc 0.935813513225256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8bd043b2f248f885ee9201127bb243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.8966530710172744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754350533fe14ab39aa6f4910be1afb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.018985044211149216 train acc 1.0\n",
      "epoch 4 batch id 201 loss 0.17662766575813293 train acc 0.9682835820895522\n",
      "epoch 4 batch id 401 loss 0.20021408796310425 train acc 0.9659445137157108\n",
      "epoch 4 batch id 601 loss 0.0823211818933487 train acc 0.9645902662229617\n",
      "epoch 4 batch id 801 loss 0.04671482369303703 train acc 0.9651217228464419\n",
      "epoch 4 batch id 1001 loss 0.19085052609443665 train acc 0.9654408091908092\n",
      "epoch 4 batch id 1201 loss 0.2113514393568039 train acc 0.9657316819317235\n",
      "epoch 4 batch id 1401 loss 0.04337078332901001 train acc 0.9655380085653105\n",
      "epoch 4 batch id 1601 loss 0.06009234860539436 train acc 0.9651584946908183\n",
      "epoch 4 batch id 1801 loss 0.176896333694458 train acc 0.9652970571904498\n",
      "epoch 4 batch id 2001 loss 0.11116272211074829 train acc 0.9651268115942029\n",
      "epoch 4 batch id 2201 loss 0.2176637202501297 train acc 0.9652430713312131\n",
      "epoch 4 batch id 2401 loss 0.0855502039194107 train acc 0.9655221782590587\n",
      "epoch 4 batch id 2601 loss 0.06716382503509521 train acc 0.9657823913879278\n",
      "epoch 4 batch id 2801 loss 0.07509464025497437 train acc 0.9659273473759372\n",
      "epoch 4 batch id 3001 loss 0.052489906549453735 train acc 0.9658655448183938\n",
      "epoch 4 batch id 3201 loss 0.015774885192513466 train acc 0.9659774289284598\n",
      "epoch 4 batch id 3401 loss 0.14915616810321808 train acc 0.96608534254631\n",
      "epoch 4 batch id 3601 loss 0.01078161783516407 train acc 0.9662159816717578\n",
      "epoch 4 batch id 3801 loss 0.1808084398508072 train acc 0.9662177716390423\n",
      "epoch 4 batch id 4001 loss 0.014494618400931358 train acc 0.9664302674331418\n",
      "epoch 4 batch id 4201 loss 0.1340869963169098 train acc 0.9665927755296359\n",
      "epoch 4 batch id 4401 loss 0.10982349514961243 train acc 0.9666908089070666\n",
      "epoch 4 batch id 4601 loss 0.07931981980800629 train acc 0.966773527494023\n",
      "epoch 4 train acc 0.9667902090443686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679c61768f284c93844b536a785feeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.8983925143953935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7823cdc3fa74255b1fd42fbd6d3fe25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.01645178347826004 train acc 1.0\n",
      "epoch 5 batch id 201 loss 0.08279287815093994 train acc 0.9849191542288557\n",
      "epoch 5 batch id 401 loss 0.008490854874253273 train acc 0.982465710723192\n",
      "epoch 5 batch id 601 loss 0.12317541241645813 train acc 0.9823731281198004\n",
      "epoch 5 batch id 801 loss 0.0051270113326609135 train acc 0.9822877652933832\n",
      "epoch 5 batch id 1001 loss 0.003696909872815013 train acc 0.9826111388611388\n",
      "epoch 5 batch id 1201 loss 0.16133549809455872 train acc 0.9824104912572856\n",
      "epoch 5 batch id 1401 loss 0.00849701277911663 train acc 0.9822002141327623\n",
      "epoch 5 batch id 1601 loss 0.0047793020494282246 train acc 0.982237663960025\n",
      "epoch 5 batch id 1801 loss 0.18387871980667114 train acc 0.9821973903387007\n",
      "epoch 5 batch id 2001 loss 0.2534700334072113 train acc 0.9820246126936532\n",
      "epoch 5 batch id 2201 loss 0.011350002139806747 train acc 0.9819542253521126\n",
      "epoch 5 batch id 2401 loss 0.026777297258377075 train acc 0.9817914410662224\n",
      "epoch 5 batch id 2601 loss 0.005736354272812605 train acc 0.981905997693195\n",
      "epoch 5 batch id 2801 loss 0.18988758325576782 train acc 0.9818926276329882\n",
      "epoch 5 batch id 3001 loss 0.005377972032874823 train acc 0.9820268243918694\n",
      "epoch 5 batch id 3201 loss 0.14405150711536407 train acc 0.9821735395189003\n",
      "epoch 5 batch id 3401 loss 0.08622086048126221 train acc 0.9820640987944722\n",
      "epoch 5 batch id 3601 loss 0.004926948808133602 train acc 0.9821577339627882\n",
      "epoch 5 batch id 3801 loss 0.018769696354866028 train acc 0.9821099710602473\n",
      "epoch 5 batch id 4001 loss 0.0120617700740695 train acc 0.9821372781804549\n",
      "epoch 5 batch id 4201 loss 0.013065756298601627 train acc 0.9821471078314687\n",
      "epoch 5 batch id 4401 loss 0.1040850356221199 train acc 0.9821134401272438\n",
      "epoch 5 batch id 4601 loss 0.18056192994117737 train acc 0.9821777874375136\n",
      "epoch 5 train acc 0.9821952325085325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bf1306478842d996dd95117d044f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.896853007037748\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(notebook.tqdm(train_dataloader)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "\n",
    "        if batch_id % 200 == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "            \n",
    "\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    train_loss_kobert_per_epoch.append(loss.data.cpu().numpy())\n",
    "    train_accuracy_kobert_per_epoch.append(train_acc / (batch_id+1))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(notebook.tqdm(test_dataloader)):\n",
    "\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "    \n",
    "    kobert_accuracy = test_acc / (batch_id+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "    * 임의의 input 문장이 들어왔을 때 긍정/부정 판별\n",
    "    * 두 개의 모델 Accuracy 비교\n",
    "    * 학습 내용 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text classification with KoBert\n",
    "def predict_input_text(text):\n",
    "    transform = nlp.data.BERTSentenceTransform(\n",
    "                tokenizer.tokenize, max_seq_length=128, vocab=vocab, pad=True, pair=False)\n",
    "\n",
    "    sentence = text\n",
    "    sentence = transform([sentence])\n",
    "\n",
    "    sentence_dataloader = DataLoader(sentence, batch_size=1, shuffle=False)\n",
    "\n",
    "    token_ids, valid_length, segment_ids = sentence_dataloader\n",
    "    token_ids = token_ids.long().to(device)\n",
    "    segment_ids = segment_ids.long().to(device)\n",
    "    valid_length= valid_length\n",
    "\n",
    "    out = model(token_ids, valid_length, segment_ids)\n",
    "    predict = torch.max(out, 1)[1].item()\n",
    "    if predict == 0:\n",
    "        return \"부정적인 문장입니다\"\n",
    "    else:\n",
    "        return \"긍정적인 문장입니다\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'부정적인 문장입니다'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_input_text('이건 좀... 아니지 않니..?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_multilingual_cased_accuracy : 0.8555933179723503\n",
      "kobert_accuracy : 0.896853007037748\n"
     ]
    }
   ],
   "source": [
    "print(f\"bert_base_multilingual_cased_accuracy : {bert_base_multilingual_cased_accuracy}\")\n",
    "print(f\"kobert_accuracy : {kobert_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=['bert_base_multilingual_cased_accuracy', 'kobert_accuracy'], y=[bert_base_multilingual_cased_accuracy, kobert_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the loss bert_multilingual and kobert\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(epochs), train_loss_kobert_per_epoch, label='kobert')\n",
    "plt.plot(range(epochs), train_loss_bert_multilingual_cased_per_epoch, label='bert_multilingual')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHgCAYAAADg78rsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABYcElEQVR4nO3dd3hUZd7G8e8vnRRKCITea+gYAbuCIFbEXlfU1W32smvvrruua3ffXVdZy7oqKiBWQEXsSi8JvYeWUAIkIaTM8/4xA8QYYIBMzmRyf66Li5kzZ5L77LDJ7XOecx5zziEiIiIi4SHK6wAiIiIispfKmYiIiEgYUTkTERERCSMqZyIiIiJhROVMREREJIyonImIiIiEkRivA1SXtLQ0165dO69jiIiIiBzQjBkzNjnnmlT1WsSUs3bt2jF9+nSvY4iIiIgckJmt2tdrOq0pIiIiEkZUzkRERETCiMqZiIiISBiJmDlnVSktLSUnJ4fi4mKvo0gIJCQk0KpVK2JjY72OIiIiUm0iupzl5OSQkpJCu3btMDOv40g1cs6xefNmcnJyaN++vddxREREqk1En9YsLi6mcePGKmYRyMxo3LixRkVFRCTiRHQ5A1TMIpg+WxERiUQRX868tnLlSnr27BnUvieeeOJh3att5cqV/O9//zvk94uIiIj3VM4iRFlZmcqZiIhIBFA5q0HLly+nX79+TJs2jUGDBtG7d29GjhzJ1q1b9+zz+uuv07dvX3r27MlPP/0EQGFhIVdddRUDBgygX79+vP/++wC88sornHXWWQwePJghQ4Zwxx138PXXX9O3b1+eeuopT45RREREDk9EX61Z0YMfZJG9bnu1fs2MFvW5/8weQe27aNEiLrroIl555RUuv/xynnvuOU444QTuu+8+HnzwQZ5++mkAioqKmD17Nl999RVXXXUV8+fP59FHH2Xw4MGMHj2a/Px8BgwYwMknnwzAzJkzmTt3LqmpqXz55Zc88cQTfPjhh9V6nCIiIlJz6kw581JeXh4jRoxg7NixtGzZkvz8fE444QQArrjiCs4///w9+1588cUAHH/88Wzfvp38/HwmTZrEhAkTeOKJJwD/VairV68GYOjQoaSmptbwEYmIiEio1JlyFuwIVyg0aNCANm3a8M0333DhhRfud9/KVyCaGc453nvvPbp27fqz13788UeSkpKqPa+IiIh4R3POakBcXBzjxo3jtdde46OPPqJRo0Z8/fXXgH+O2e5RNIC3334bgG+++YYGDRrQoEEDTjnlFJ577jmccwDMmjWryu+TkpLCjh07Qnw0IiIiEkp1ZuTMa0lJSXz44YcMHTqUc889l9tvv52ioiI6dOjAf/7znz37JSQk0K9fP0pLSxk9ejQA9957LzfddBO9e/fG5/PRvn37KueV9e7dm+joaPr06cOoUaO4+eaba+z4REREpHrY7tGY2i4zM9NVvkfYggUL6N69u0eJpCboMxYRkdrIzGY45zKrek2nNUVEREQCyn2ODdu8XRpQpzVFRESkTisuLee7ZZuYlLWRzxZspElKAp/ceJxneVTOREREpM7ZtrOULxflMilrI18uyqWwpJzk+BhO7NqEYT2a4ZzzbA1nlTMRERGpEzZsK2bygo1MytrA98s2U+ZzpCXHc1bflpzSI52jOjYmPiba65ihLWdmNhx4BogGXnLO/aXS622B0UATYAtwmXMuJ/Da48Dp+OfFTQZudJFy9YKIiIjUiKW5BUzM2sCk7I3MWZMPQPu0JK4+rj3DMprRr3VDoqK8GSHbl5CVMzOLBl4AhgI5wDQzm+Ccy66w2xPAa865V81sMPAYcLmZHQ0cA/QO7PcNcALwZajyioiISO3n8zlm5+QzKWsjk7I3sDyvEIA+rRpw+yldGZaRTqemyZ6dsgxGKEfOBgBLnXPLAczsLWAEULGcZQC3BB5PAcYHHjsgAYgDDIgFNoYwq4iIiNRSJWU+vl++mUlZG5icvZHcHbuIiTIGdWjMqKPbcXL3dFo0rOd1zKCF8lYaLYE1FZ7nBLZVNAc4J/B4JJBiZo2dc9/jL2vrA38mOucWVP4GZnatmU03s+l5eXnVfgDVYeXKlfTs2fOQ3z9+/Hiys7MPvONhGDVqFO+++y4ATz/9NEVFRXteO+2008jPzwcgOTkZgHXr1nHeeeeFNFNlu7+3iIgIwI7iUj6cu47r35zFEQ9P5orRPzFu1lqOaNuIpy/sy4x7hvLfXw/kV0e1q1XFDLy/IOA24HkzGwV8BawFys2sE9AdaBXYb7KZHeec+7rim51zLwIvgv8mtDWWuoaUlZUxfvx4zjjjDDIyMmrkez799NNcdtllJCYmAvDxxx//Yp8WLVrsKXMiIiI1JXdHMZ9l5zIpewPfLd1MSbmP1KQ4Tu3VjFN6NOOYTmkkxHo/of9whbKcrQVaV3jeKrBtD+fcOgIjZ2aWDJzrnMs3s2uAH5xzBYHXPgGOAn5Wzg7KJ3fAhnmH/PYqNesFp/7lgLuVlZVx6aWXMnPmTHr06MFrr73GggULuOWWWygoKCAtLY1XXnmF5s2bc+KJJ9K3b1+++eYbRo4cyYQJE5g6dSqPPPII7733Hh07dvzF1z/xxBPp168fX3/9NYWFhbz22ms89thjzJs3jwsvvJBHHnmElStXcsYZZzB//nwAnnjiCQoKCnjggQf2fJ1nn32WdevWcdJJJ5GWlsaUKVNo164d06dPJy0tbc9+Fb/WK6+8woQJEygqKmLZsmWMHDmSxx9/HICXX36Zv/71rzRs2JA+ffoQHx/P888/z6hRozjjjDP2jL4lJydTUFBAQUEBI0aMYOvWrZSWlvLII48wYsSIw/mERESklluxqZBJgQn9M1dvxTlonVqPXx3VlmE9mnFE20ZEh9mE/sMVynI2DehsZu3xl7KLgEsq7mBmacAW55wPuBP/lZsAq4FrzOwx/HPOTgCeDmHWkFq0aBEvv/wyxxxzDFdddRUvvPAC48aN4/3336dJkya8/fbb3H333XvW0iwpKWH3UlRLliz5WZHZl7i4OKZPn84zzzzDiBEjmDFjBqmpqXTs2DHoNTZvuOEGnnzySaZMmfKzMnYgs2fPZtasWcTHx9O1a1euv/56oqOjefjhh5k5cyYpKSkMHjyYPn367PfrJCQkMG7cOOrXr8+mTZsYNGgQZ511VlhP2hQRkerlnGPe2m17JvQv3lgAQI8W9blpSBeG9UinW7OUiP7dELJy5pwrM7PrgIn4b6Ux2jmXZWYPAdOdcxOAE4HHzMzhP635h8Db3wUGA/PwXxzwqXPug8MKFMQIV6i0bt2aY445BoDLLruMP//5z8yfP5+hQ4cCUF5eTvPmzffsf+GFFx709zjrrLMA6NWrFz169Njz9Tp06MCaNWto2LDhYR7Fvg0ZMoQGDRoAkJGRwapVq9i0aRMnnHACqampAJx//vksXrx4v1/HOcddd93FV199RVRUFGvXrmXjxo00a9YsZNlFRMR7peU+flqxhYmBCf3rtxUTZTCgfSr3nZHBsB7ptGqU6HXMGhPSOWfOuY+Bjyttu6/C43fxF7HK7ysHfhPKbDWpcrtPSUmhR48efP/991Xun5SUdNDfIz4+HoCoqKg9j3c/LysrIyYmBp/Pt2d7cXH1rRtW8ftFR0dTVla23/0rZvH5fJSUlADwxhtvkJeXx4wZM4iNjaVdu3bVmlNERMJHUUkZUxflMSl7I58v2Mj24jISYqM4vnMTbh3WlcHdmpKaFOd1TE9o4fMasHr16j1F7H//+x+DBg0iLy9vz7bS0lKysrKqfG9KSgo7duw47Azp6enk5uayefNmdu3axYcffhjS73fkkUcydepUtm7dSllZGe+9996e19q1a8eMGTMAmDBhAqWlpQBs27aNpk2bEhsby5QpU1i1atVh5xARkfCxuWAXY6at4devTqPfQ5P53RszmbIol6EZzfjX5Ucw695hvPirTM47olWdLWbg/dWadULXrl154YUXuOqqq8jIyOD666/nlFNO4YYbbmDbtm2UlZVx00030aNHj1+896KLLuKaa67h2Wef5d13363ygoBgxMbGct999zFgwABatmxJt27dqtzv2muvZfjw4bRo0YIpU6Yc0vcCaNmyJXfddRcDBgwgNTWVbt267Tn1ec011zBixAj69OnD8OHD94wUXnrppZx55pn06tWLzMzMfWYUEZHaY82Woj136J++cgs+By0b1uPiAW0Y1iOdAe1SiYnWWFFFFikrImVmZrrdk+h3W7BgAd27d/cokRQUFJCcnExZWRkjR47kqquuYuTIkdX6PfQZi4iEF+cc2eu3MylrIxOzNrBwg/9sTLdmKQzLSGdYj2b0aFE/oif0B8PMZjjnMqt6TSNnEjIPPPAAn332GcXFxQwbNoyzzz7b60giIhICZeU+pq/a6h8hy9rI2vydmEFm20bcc3p3hmak07bxwc+nrqtUzmqRP/zhD3z77bc/23bjjTdy5ZVXepRo/5544gmvI4iISIgUl5bz1eK9E/q3FpUSFxPFcZ3SuGFIJ4Z0TyctOf7AX0h+QeWsFnnhhRe8jiAiInVYflEJny/w36H/q8Wb2FlaTkpCDEO6NWVYj2ac0KUJSfGqFocr4v8XdM7V+fPakSpS5kuKiISztfk7mZy1gYlZG/lp5RbKfY5m9RM4P7MVwzKaMbBDKrGa0F+tIrqcJSQksHnzZho3bqyCFmGcc2zevJmEhASvo4iIRBTnHIs3FgSusNzA/LXbAejUNJnfntCBYRnN6NWyAVERtmRSOInoctaqVStycnLIy8vzOoqEQEJCAq1atfI6hohIrVfuc8xcvXXPGparNhcB0L9NQ+44tRtDM9Lp2CTZ45R1R0SXs9jYWNq3b+91DBERkbBTXFrOd8s2MSlrI58t2MimghJio42jO6Zx7fEdGNo9nab1dXbCCxFdzkRERGSvbTtL+XJRLpOyNvLlolwKS8pJjo/hxK5NOKVHM07s2oSUhFivY9Z5KmciIiIRbMO2YiZn+09Xfr9sM2U+R5OUeEb0a8mwjHSO6tiY+Jhor2NKBSpnIiIiEWZpbsGeJZPmrMkHoH1aElcf155hGc3o17qhJvSHMZUzERGRWs7nc8zOyWdS1kYmZW9geV4hAH1aNeD2U7oyLCOdTk2TdeeCWkLlTEREpBYqKfPx/fLNTMrawOTsjeTu2EVMlDGoQ2OuPLodJ2ek07xBPa9jyiFQORMREakldhSXMnVxHhOzNvLlwlx27CojMS6aE7s2YVhGM07q2pQGiZrQX9upnImIiISx3B3FfJbtXzLpu6WbKSn30TgpjtN6NWdYj3SO6ZRGQqwm9EcSlTMREZEws2JT4Z4bws5cvRXnoE1qIr86qi2n9GxG/zaNiNaE/oilciYiIuIx5xzz1m7bM6F/8cYCAHq0qM/NJ3dhWI90uqanaEJ/HaFyJiIi4oHSch8/rdjCxMCE/vXbiomOMga0S+X+M9swNCOdVo0SvY4pHlA5ExERqSFFJWVMXZTHpOyNfL5gI9uLy0iIjeL4zk24dVhXhnRrSqOkOK9jisdUzkREREJoc8EuPl/gn9D/9ZJN7Crz0TAxlqEZzRjWI53jOzehXpwm9MteKmciIiLVbM2WIv8d+rM2Mn3VFnwOWjasxyUD2zAsoxlHtmtETHSU1zElTKmciYiIHCbnHNnrtzMpayMTszawcMMOALo1S+G6wZ0ZlpFOjxb1NaFfgqJyJiIicgjKyn1MW7mVSdn+EbK1+TsxgyPbpnLP6d0ZmpFO28ZJXseUWkjlTEREJEg7S8r5esneCf1bi0qJi4niuE5p3DCkE0O6p5OWHO91TKnlVM5ERET2I7+oZM+E/qmL8ygu9VE/IYYh3dMZlpHO8V2akBSvX6dSffSvSUREpJJtO0sZNzOHiVkb+WnlFsp9jmb1E7ggszXDMpoxsEMqsZrQLyGiciYiIhLgnOODuet56INsNhXsonPTZH57QgeGZTSjd6sGmtAvNULlTEREBP/tL+59fz5fLsqjV8sGjB6VSe9WDb2OJXWQypmIiNRpZeU+Rn+7gqcmL8EM7jsjgyuObqeFxcUzKmciIlJnzc3J586x88hat52TuzflwRE9admwntexpI5TORMRkTqncFcZf5+0mFe+W0Facjz/d2l/hvdspjllEhZUzkREpE75LHsj970/n/Xbi7l0YBv+OLwb9RNivY4lsofKmYiI1AkbtxfzwIQsPpm/gS7pybx7yVEc0TbV61giv6ByJiIiEc3nc7zx02oe/2Qhu8p93H5KV645rgNxMbpPmYQnlTMREYlYizbs4K5x85ixaivHdGrMo2f3ol2a1ruU8KZyJiIiEae4tJznvljCv6YuJyUhhr+f34dz+rfUhH+pFVTOREQkony7dBN3j5vHys1FnNO/JfecnkFqUpzXsUSCpnImIiIRYUthCY98lM3YmWtp1ziRN349kGM6pXkdS+SgqZyJiEit5pxj7My1PPJRNjuKy/jDSR25fnBnEmKjvY4mckhUzkREpNZauamQu8fP49ulm+nfpiGPndObrs1SvI4lclhCWs7MbDjwDBANvOSc+0ul19sCo4EmwBbgMudcTuC1NsBLQGvAAac551aGMq+IiNQOJWU+/v31cp79fAlx0VE8cnZPLhnQhiithykRIGTlzMyigReAoUAOMM3MJjjnsivs9gTwmnPuVTMbDDwGXB547TXgUefcZDNLBnyhyioiIrXHjFVbuWvsPBZt3MFpvZpx/5k9SK+f4HUskWoTypGzAcBS59xyADN7CxgBVCxnGcAtgcdTgPGBfTOAGOfcZADnXEEIc4qISC2wvbiUxz9dyBs/rqZ5/QRe+lUmJ2ekex1LpNqFspy1BNZUeJ4DDKy0zxzgHPynPkcCKWbWGOgC5JvZWKA98Blwh3OuPIR5RUQkDDnn+HT+Bu6fkMWmgl2MOrodtw7rSnK8pk1LZPL6X/ZtwPNmNgr4ClgLlOPPdRzQD1gNvA2MAl6u+GYzuxa4FqBNmzY1lVlERGrIuvyd3Pf+fD5bkEtG8/q8dEUmvVs19DqWSEiFspytxT+Zf7dWgW17OOfW4R85IzCv7FznXL6Z5QCzK5wSHQ8MolI5c869CLwIkJmZ6UJzGCIiUtPKfY5Xv1vJE5MW4RzcfVp3rjymHTHRWg9TIl8oy9k0oLOZtcdfyi4CLqm4g5mlAVuccz7gTvxXbu5+b0Mza+KcywMGA9NDmFVERMLE/LXbuGvcPObmbOPErk14eERPWqcmeh1LpMaErJw558rM7DpgIv5baYx2zmWZ2UPAdOfcBOBE4DEzc/hPa/4h8N5yM7sN+Nz8C6HNAP4dqqwiIuK9opIynv5sCS9/s4JGibE8d3E/zujdXOthSp1jzkXG2cDMzEw3fboG10REaqMpi3K5Z9x81ubv5OIBrbljeHcaJMZ6HUskZMxshnMus6rXvL4gQERE6rC8Hbt46MNsPpizjo5Nkhjzm6MY0D7V61ginlI5ExGRGufzOcZMX8OfP15AcamPm0/uwm9P7EB8jNbDFFE5ExGRGrU0dwd3jZ3PTyu3MLB9Kn8+pxcdmyR7HUskbKiciYhIjSguLecfXy7j/75cSmJcDI+f25vzM1tpwr9IJSpnIiIScj8s38xd4+axPK+QEX1bcO8ZGaQlx3sdSyQsqZyJiEjI5BeV8OePFzBmeg6tU+vx6lUDOKFLE69jiYQ1lTMREal2zjkmzFnHwx9ms7WolN+c0IGbhnShXpwm/IsciMqZiIhUqzVbirh7/Hy+WpxHn9YNee2qXmS0qO91LJFaQ+VMRESqRWm5j5e/WcHTny0m2owHzszg8qPaER2lCf8iB0PlTEREDtvsNfnc8d5cFm7YwdCMdB48qwctGtbzOpZIraRyJiIih6xgVxlPTFzEq9+vpGlKPP+87AiG92zmdSyRWk3lTEREDsmkrA3cPyGLDduLuXxQW247pSv1E7QepsjhUjkTEZGDsmFbMfdPmM/ErI10a5bCC5f2p3+bRl7HEokYKmciIhKUcp/jjR9X8finiygt9/HH4V255rgOxEZHeR1NJKKonImIyAEtWL+dO8fOY/aafI7rnMYjZ/ekbeMkr2OJRCSVMxER2afi0nKe+XwJ//5qOfXrxfLUhX04u29LrYcpEkIqZyIiUqWvl+Rx97j5rN5SxHlHtOLu07rTKCnO61giEU/lTEREfmZzwS4e+WgB42atpX1aEv+7ZiBHd0zzOpZInaFyJiIigH89zHdn5PDoxwso3FXGDYM78fuTOpEQq/UwRWqSypmIiLA8r4C7x83n++WbyWzbiMfO6UXn9BSvY4nUSSpnIiJ1WEmZj39NXcZzU5YSHxPFoyN7cvGRbYjSepginlE5ExGpo6av3MKdY+exJLeA03s35/4zMmhaP8HrWCJ1nsqZiEgds21nKX/9dCH/+3E1LRvWY/SoTAZ3S/c6logEqJyJiNQRzjk+nreBBz7IYnPBLq4+tj23DO1CUrx+FYiEE/0/UkSkDsjZWsR972fxxcJcerasz+grjqRXqwZexxKRKqiciYhEsLJyH698t5K/T1oMwD2nd2fU0e2I0XqYImFL5UxEJELNX7uNO8bOZf7a7Qzu1pSHRvSgVaNEr2OJyAGonImIRJjCXWU8NXkxo79dQWpSPM9f0o/TezXXepgitYTKmYhIBPli4UbuHZ/F2vydXDKwDX8a3o0G9WK9jiUiB0HlTEQkAuRuL+bBD7L5aN56OjdN5p3fHsWR7VK9jiUih0DlTESkFvP5HG9OW81fPlnIrjIftw7twm9O6EhcjCb8i9RWKmciIrXU4o07uGvsPKav2sqgDqn8eWQvOjRJ9jqWiBwmlTMRkVqmuLScF6Ys5Z9Tl5EUH8PfzuvNeUe00oR/kQihciYiUot8t2wTd4+bz4pNhYzs15J7Tu9O4+R4r2OJSDVSORMRqQW2Fpbw6McLeHdGDm1SE3n96gEc17mJ17FEJARUzkREwphzjvGz1/LwhwvYvrOU353YkRsGd6ZeXLTX0UQkRFTORETC1KrNhdwzfj5fL9lE39YNeeycXnRvXt/rWCISYipnIiJhprTcx7+/Xs4zny0hNjqKh0b04NKBbYmO0oR/kbpA5UxEJIzMXL2Vu8bOY+GGHZzSI50Hz+pJswYJXscSkRqkciYiEgZ2FJfyt4mLeP2HVaSnJPDi5UcwrEczr2OJiAdUzkREPPbp/A3cP2E+uTt2ccVR7bjtlK4kx+vHs0hdpf/3i4h4ZP22ndz3fhaTszfSvXl9/nV5Jn1bN/Q6loh4TOVMRKSGlfscr3+/kr9NXES5c9xxajeuPrY9sdFaD1NEQlzOzGw48AwQDbzknPtLpdfbAqOBJsAW4DLnXE6F1+sD2cB459x1ocwqIlITstdt585x85izJp/jOqfx6Nm9aNM40etYIhJGQlbOzCwaeAEYCuQA08xsgnMuu8JuTwCvOedeNbPBwGPA5RVefxj4KlQZRURqys6Scp7+fDEvfb2ChvVieeaivpzVp4XWwxSRXwjlyNkAYKlzbjmAmb0FjMA/ErZbBnBL4PEUYPzuF8zsCCAd+BTIDGFOEZGQmro4j3vGz2PNlp1ckNmKu07rTsPEOK9jiUiYCmU5awmsqfA8BxhYaZ85wDn4T32OBFLMrDGwFfg7cBlwcggzioiEzKaCXTz8YTbvz15HhyZJvHXtIAZ1aOx1LBEJc15fEHAb8LyZjcJ/+nItUA78HvjYOZezvyF/M7sWuBagTZs2IQ8rIhIM5xxjpq/hzx8vpKikjBuHdOb3J3UkPkbrYYrIgYWynK0FWld43iqwbQ/n3Dr8I2eYWTJwrnMu38yOAo4zs98DyUCcmRU45+6o9P4XgRcBMjMzXciOREQkSMvyCrhr7Dx+XLGFAe1S+fM5PenUNMXrWCJSi4SynE0DOptZe/yl7CLgkoo7mFkasMU55wPuxH/lJs65SyvsMwrIrFzMRETCya6ycv755XJemLKUhNgoHjunFxdmtiZK62GKyEEKWTlzzpWZ2XXARPy30hjtnMsys4eA6c65CcCJwGNm5vCf1vxDqPKIiITKTyu2cOfYuSzLK+TMPi2494zuNE3RepgicmjMucg4G5iZmemmT5/udQwRqUO2FZXy2CcLeGvaGlo2rMcjI3tyUtemXscSkVrAzGY456q8G4XXFwSIiNQ6zjk+mLuehz7IZmtRCdce34GbTu5MYpx+pIrI4dNPEhGRg7BmSxH3vj+fLxfl0atlA1658kh6tmzgdSwRiSAqZyIiQSgr9zH62xU8NXkJZnDfGRlccXQ7ojXhX0SqmcqZiMgBzM3J586x88hat50h3Zry0Nk9admwntexRCRCqZyJiOxDUUkZT0xczCvfrSAtOZ5/XNqfU3s203qYIhJSKmciIlWYv3YbN7w1i+V5hVw2qA1/HN6N+gmxXscSkTpA5UxEpAKfzzH62xU8/ukiGibG8savB3JMpzSvY4lIHaJyJiISkLdjF7e9M4epi/M4uXs6j5/Xm9SkOK9jiUgdo3ImIgJ8uSiX296Zw47iMh4+uyeXDWyjuWUi4gmVMxGp03aVlfPXTxYx+tsVdE1P4Y1fD6JrMy1ULiLeUTkTkTprae4Orn9zNgvWb+eKo9py52ndSYiN9jqWiNRxKmciUuc453jzpzU89GEW9WKjeelXmZycke51LBERQOVMROqY/KIS7nhvHp9mbeDYTmn8/YI+pNdP8DqWiMgeKmciUmf8sHwzN789m7wdu7jz1G5cc1wHorT8koiEGZUzEYl4peU+nv18Cc9PWUq7xkmM/f3R9G7V0OtYIiJVUjkTkYi2enMRN749i1mr8zn/iFY8cFYPkuL1o09Ewpd+QolIxHp/9lruHjcfM3j24n6c1aeF15FERA5I5UxEIk7BrjLuGz+fsbPWckTbRjx9YV9apyZ6HUtEJCgqZyISUWavyefGt2axZksRNw7pzPWDOxETHeV1LBGRoKmciUhEKPc5/jl1GU9NXkzTlHjeuvYoBrRP9TqWiMhBUzkTkVpvw7Zibn57Nt8v38zpvZrz55G9aJAY63UsEZFDonImIrXapKwN/PG9uewq9fH4ub05P7OVFiwXkVpN5UxEaqXi0nIe+Sib//6wmp4t6/PMRf3o2CTZ61giIodN5UxEap0F67dzw5uzWJJbwDXHtee2U7oSH6MFy0UkMqiciUit4Zzj1e9W8udPFlI/IZbXrhrA8V2aeB1LRKRaqZyJSK2wuWAXt787ly8W5nJS1yb87fw+pCXHex1LRKTaqZyJSNj7ekket4yZw7adpTxwZgZXHN1Ok/5FJGKpnIlI2Cop8/HEpEW8+NVyOjVN5rWrBtC9eX2vY4mIhJTKmYiEpeV5Bdzw1izmr93OpQPbcM/pGdSL06R/EYl8KmciElacc7wzI4cHJmQRFxPFvy4/glN6NPM6lohIjVE5E5GwsW1nKXeNm8dHc9czqEMqT13Yl+YN6nkdS0SkRqmciUhYmL5yCze+NZsN24u5/ZSu/PaEjkRHadK/iNQ9Kmci4qmych/PT1nKs58voVWjRN797VH0a9PI61giIp5RORMRz+RsLeKmt2YzfdVWRvZryUMjepCSoAXLRaRuUzkTEU98OHcdd46dh3Pw1IV9GNmvldeRRETCwgHLmZn1cs7Nq4kwIhL5CneV8eAHWYyZnkPf1g159qJ+tGmc6HUsEZGwEczI2T/MLB54BXjDObcttJFEJFLNy9nGjW/NYsXmQq47qRM3ntyZ2Ogor2OJiISVA5Yz59xxZtYZuAqYYWY/Af9xzk0OeToRiQg+n+Olb5bzt4mLaJwUz/9+PYijOjb2OpaISFgKas6Zc26Jmd0DTAeeBfqZf2G7u5xzY0MZUERqt9ztxdz6zhy+XrKJU3qk85dzetMoKc7rWCIiYSuYOWe9gSuB04HJwJnOuZlm1gL4HlA5E5EqfbFwI7e9M5eikjL+PLIXFw9orQXLRUQOIJiRs+eAl/CPku3cvdE5ty4wmiYi8jPFpeX85ZOFvPLdSro1S+G5iwfROT3F61giIrVCMOXsdGCnc64cwMyigATnXJFz7vWQphORWmfxxh3c8OYsFm7YwZXHtONPw7uREKsFy0VEghXMZVKfARUXt0sMbDsgMxtuZovMbKmZ3VHF623N7HMzm2tmX5pZq8D2vmb2vZllBV67MJjvJyLecc7x+g+rOPO5b8jbsYv/jDqS+8/soWImInKQghk5S3DOFex+4pwrMLMD3pTIzKKBF4ChQA4wzcwmOOeyK+z2BPCac+5VMxsMPAZcDhQBvwpciNAC/1WiE51z+UEfmYjUmK2FJfzpvblMyt7IcZ3T+PsFfWiakuB1LBGRWimYclZoZv2dczMBzOwIYOcB3gMwAFjqnFseeN9bwAigYjnLAG4JPJ4CjAdwzi3evUNgblsu0ATID+L7ikgN+m7ZJm5+ezZbCku45/TuXHVMe6K0YLmIyCELppzdBLxjZusAA5oBwZxmbAmsqfA8BxhYaZ85wDnAM8BIIMXMGjvnNu/ewcwGAHHAsiC+p4jUkNJyH09NXsz/TV1G+7QkXr7iSHq2bOB1LBGRWi+Ym9BOM7NuQNfApkXOudJq+v63Ac+b2SjgK2AtUL77RTNrDrwOXOGc81V+s5ldC1wL0KZNm2qKJCIHsmpzITe8OYs5Odu4MLM195+VQWKcluoVEakOwf407Yr/FGQC0N/McM69doD3rAVaV3jeKrBtD+fcOvwjZ5hZMnDu7nllZlYf+Ai42zn3Q1XfwDn3IvAiQGZmpgvyWETkMIydmcO94+cTHWW8cEl/Tu/d3OtIIiIRJZib0N4PnIi/nH0MnAp8AxyonE0DOptZe/yl7CLgkkpfOw3YEhgVuxMYHdgeB4zDf7HAuwdxPCISIjuKS7l3/HzGz17HgHapPHVRX1o2rHfgN4qIyEEJZuTsPKAPMMs5d6WZpQP/PdCbnHNlZnYdMBGIBkY757LM7CFgunNuAv7S95iZOfynNf8QePsFwPFA48ApT4BRzrnZQR+ZiFSbmau3cuNbs1iXX8wtQ7vwh5M6Ea1J/yIiIRFMOdvpnPOZWVngVGMuPz9duU/OuY/xj7ZV3HZfhcfvAr8YGXPO/ZcgCqCIhFa5z/F/Xy7lqc+W0Kx+AmN+M4gj2qZ6HUtEJKIFU86mm1lD4N/ADKAA/5qaIhLB1uXv5Oa3Z/Pjii2c2acFj5zdkwb1Yr2OJSIS8fZbzsy/QvFjgUn6/zSzT4H6zrm5NRFORLzx6fz1/Om9eZSW+3ji/D6c27+lFiwXEakh+y1nzjlnZh8DvQLPV9ZEKBHxxs6Sch76MJs3f1pN71YNeOaifrRPS/I6lohInRLMac2ZZnakc25ayNOIiGey1m3jhjdnsSyvkN+c0IFbh3YlLiaY5XdFRKQ6BVPOBgKXmtkqoBD/KgHOOdc7pMlEpEY45xj97Ur++slCGibG8t+rB3Js5zSvY4mI1FnBlLNTQp5CRDyRt2MXt787hy8X5XFy96b89dzeNE6O9zqWiEidFkw50533RSLQ1MV53DpmDtuLS3loRA8uH9RWk/5FRMJAMOXsI/wFzfAv39QeWAT0CGEuEQmRXWXl/O3TRbz0zQq6pCfzxq8H0rVZitexREQkIJiFz3tVfG5m/YHfhyyRiITM0twCbnhzFtnrt/Oro9py12ndSYiN9jqWiIhUEOzC53s452aa2cBQhBGR0HDO8fa0NTz4QTYJsVH8+1eZDM1I9zqWiIhUIZiFz2+p8DQK6A+sC1kiEalW24pKuXPcXD6et4FjOjXmyQv6kl4/wetYIiKyD8GMnFWcjFKGfw7ae6GJIyLV6acVW7jprVnk7tjFHad249rjOhClBctFRMJaMHPOHqyJICJSfcrKfTz7+RKen7KUNqmJvPe7o+nTuqHXsUREJAjBnNacDJwfWF8TM2sEvOWc0/3PRMLQmi1F3PjWLGauzue8I1rxwFk9SI4/6OmlIiLikWB+YjfZXcwAnHNbzaxp6CKJyKF6f/Za7hk3H4BnL+7HWX1aeJxIREQOVjDlrNzM2jjnVgOYWVt0Y1qRsFKwq4z738/ivZk59G/TkGcu6kfr1ESvY4mIyCEIppzdDXxjZlPx34j2OODakKYSkaDNWZPPjW/NYvWWIm4Y3IkbhnQmJloLlouI1FbBXBDwaeDGs4MCm25yzm0KbSwRORCfz/Gvr5bz90mLaJoSz5vXDGJgh8ZexxIRkcMUzAUBI4EvnHMfBp43NLOznXPjQx1ORKq2cXsxN789m++Wbea0Xs14bGRvGiTGeh1LRESqQTCnNe93zo3b/cQ5l29m9wPjQ5ZKRPZpcvZG/vjuHIpLffz13F5ckNlaC5aLiESQYMpZVZNXdF2+SA0rLi3n0Y8W8PoPq8hoXp9nL+5Hp6bJXscSEZFqFkzJmm5mTwIvBJ7/AZgRukgiUtnCDdu54c1ZLN5YwK+Pbc/tw7sSH6MFy0VEIlEw5ex64F7g7cDzyfgLmoiEmHOO175fxaMfL6B+QiyvXjWAE7o08TqWiIiEUDBXaxYCd9RAFhGpYEthCX98dw6fLcjlxK5NeOL8PqQlx3sdS0REQiyYqzWbAH8EegAJu7c75waHMJdInfbNkk3cMmY2+UWl3HdGBlce006T/kVE6ohgTmu+gf+U5hnAb4ErgLxQhhKpq0rKfPx98iJe/Go5HdKSeOXKAWS0qO91LBERqUHBlLPGzrmXzexG59xUYKqZTQt1MJG6ZsWmQm54cxbz1m7j4gFtuO+MDOrFadK/iEhdE0w5Kw38vd7MTgfWAamhiyRStzjneHdGDvdPyCI2Oop/Xtaf4T2bex1LREQ8Ekw5e8TMGgC3As8B9YGbQ5pKpI7YtrOUe8bP54M56xjYPpWnL+pL8wb1vI4lIiIeCuZqzQ8DD7cBJ4U2jkjdMWPVFm54czYbthdz+yld+e0JHYmO0qR/EZG6Tnf6F6lhZeU+XpiyjGe/WEKLhgm889uj6N+mkdexREQkTKicidSgtfk7uemtWUxbuZWz+7bg4bN7kpKgBctFRGQvlTORGvLxvPXc8d5cyn2Opy7sw8h+rbyOJCIiYSiYm9DGA+cC7Sru75x7KHSxRCJHUUkZD07I5u3pa+jTuiHPXtSXto2TvI4lIiJhKpiRs/fxXwwwA9gV2jgikWX+2m3c8OYsVmwu5PcnduTmoV2IjY7yOpaIiISxYMpZK+fc8JAnEYkgPp/j5W9W8PjEhTROiueNXw/k6I5pXscSEZFaIJhy9p2Z9XLOzQt5GpEIkLujmFvHzOHrJZsYlpHOX8/tTaOkOK9jiYhILRFMOTsWGGVmK/Cf1jTAOed6hzSZSC00ZWEut70zh4JdZTxydk8uHdhGC5aLiMhBCaacnRryFCK1XHFpOX/9dCH/+XYl3Zql8Na1g+icnuJ1LBERqYWCWSFglZn1AY4LbPraOTcntLFEao8lG3dww1uzWbB+O6OObscdp3YjIVYLlouIyKEJ5lYaNwLXAGMDm/5rZi86554LaTKRMOec438/rebhD7NJjIth9KhMBndL9zqWiIjUcsGc1rwaGOicKwQws78C3+NfBF2kTtpaWMIdY+cyMWsjx3VO4+/n96Fp/QSvY4mISAQIppwZUF7heXlgm0id9P2yzdz89mw2F+7i7tO6c/Wx7YnSguUiIlJNgrkb5n+AH83sATN7APgBeDmYL25mw81skZktNbM7qni9rZl9bmZzzexLM2tV4bUrzGxJ4M8VQR6PSMiUlvv428SFXPLSD9SLi2bs747hmuM7qJiJiEi1CuaCgCfN7Ev8t9QAuNI5N+tA7zOzaOAFYCiQA0wzswnOuewKuz0BvOace9XMBgOPAZebWSpwP5AJOGBG4L1bD+LYRKrN6s1F3PDWLGavyefCzNbcd2YGSfFamlZERKrfPn+7mFl959z2QFFaGfiz+7VU59yWA3ztAcBS59zywHveAkYAFctZBnBL4PEUYHzg8SnA5N3fw8wmA8OBN4M6KpFqtGJTIWc9/w0Az1/SjzN6t/A4kYiIRLL9/af//4Az8K+p6Spst8DzDgf42i2BNRWe5wADK+0zBzgHeAYYCaSYWeN9vLflAb6fSLUrK/dxy5jZRJnxwXXH0qZxoteRREQkwu2znDnnzgj83T6E3/824HkzGwV8Bazl5xcf7JeZXQtcC9CmTZtQ5JM67p9TlzFrdT7PXdxPxUxERGrEAS8IMLPPg9lWhbVA6wrPWwW27eGcW+ecO8c51w+4O7AtP5j3BvZ90TmX6ZzLbNKkSRCRRII3f+02nv5sCWf2acGZfXQqU0REasY+y5mZJQTmm6WZWSMzSw38aUdwpxinAZ3NrL2ZxQEXARMqfY80M9ud4U5gdODxRGBY4Ps2AoYFtonUiOLScm4ZM5vUpDgeHtHD6zgiIlKH7G/O2W+Am4AW+Oed7b5fwHbg+QN9YedcmZldh79URQOjnXNZZvYQMN05NwE4EXjMzBz+05p/CLx3i5k9jL/gATwUxAUIItXmycmLWbyxgFeuPJKGiXFexxERkTrEnHP738Hs+tqwVFNmZqabPn261zEkAvy4fDMX/fsHLhnQhkdH9vI6joiIRCAzm+Gcy6zqtWDuc/acmfXEf9uLhArbX6u+iCLhoWBXGbe+M4c2qYncfXp3r+OIiEgdFMzC5/fjP/2YAXwMnAp8A6icScR5+INs1uXv5J3fHkVinG4yKyIiNS+Y5ZvOA4YAG5xzVwJ9gAYhTSXigc+yN/L29DX89oSOHNE21es4IiJSRwVTznY653xAmZnVB3L5+W0uRGq9zQW7uGPsXLo3r89NJ3fxOo6IiNRhwZy3mW5mDYF/479qswD4PpShRGqSc467x81n+84y/vvrPsTFBPPfLCIiIqERzAUBvw88/KeZfQrUd87NDW0skZozfvZaPs3awJ2ndqNbs/pexxERkTpufwuf99/fa865maGJJFJz1uXv5L73sziyXSN+fdyBlosVEREJvf2NnP098HcCkIl/kXIDegPTgaNCG00ktHw+x+3vzqHc5/j7+X2JjrIDv0lERCTE9jm5xjl3knPuJGA90D+whuURQD+qWOdSpLZ57fuVfLt0M/eekaFFzUVEJGwEM/O5q3Nu3u4nzrn5gO7OKbXa0twCHvtkISd1bcJFR+riYxERCR/BXK0518xeAv4beH4poAsCpNYqK/dx65jZJMZF89dze2Om05kiIhI+gilnVwK/A24MPP8K+L+QJRIJsX98uYw5Odv4x6X9aVo/4cBvEBERqUHB3EqjGHgq8EekVpuXs41nP1/C2X1bcFqv5l7HERER+YX93UpjjHPuAjObB7jKrzvneoc0mUg1Ky4t5+Yxs0lLjufBs3p6HUdERKRK+xs5230a84yaCCISan+buIiluQW8fvUAGiTGeh1HRESkSvssZ8659YG/V9VcHJHQ+G7ZJl7+ZgW/Oqotx3Vu4nUcERGRfdrfac0dVHE6E/+NaJ1zTuvcSK2wo7iU29+ZS/u0JO44tZvXcURERPZrfyNnKTUZRCRUHvwgm/XbdvLe744mMS6YC5RFRES8E/RvKjNrin8pJwCcc6tDkkikGk3M2sC7M3K4fnAn+rVp5HUcERGRAzrgCgFmdpaZLQFWAFOBlcAnIc4lctg2FezirrHz6NGiPtcP7ux1HBERkaAEs3zTw8AgYLFzrj0wBPghpKlEDpNzjjvHzmPHrjKeurAvcTHB/FMXERHxXjC/sUqdc5uBKDOLcs5NATJDnEvksLw3cy2Tszdy+7CudEnX9EkREak9gplzlm9myfiXbXrDzHKBwtDGEjl0OVuLeHBCFgPbp3L1se29jiMiInJQghk5GwEUATcDnwLLgDNDGUrkUPl8jtvfmYvPOZ44vw9RUVrUXEREapdgRs5+A7ztnFsLvBriPCKH5T/freT75Zt5/NzetE5N9DqOiIjIQQtm5CwFmGRmX5vZdWaWHupQIodiycYd/PXThZzcvSnnZ7byOo6IiMghOWA5c8496JzrAfwBaA5MNbPPQp5M5CCUlvu4ZcwckuNjeOyc3pjpdKaIiNROB3O79FxgA7AZaBqaOCKH5vkvljJv7Tb+eVl/mqTEex1HRETkkAVzE9rfm9mXwOdAY+Aa51zvUAcTCdbsNfk8P2Up5/RvyfCezb2OIyIicliCGTlrDdzknJsd4iwiB21nSTm3jJlNeko895/Zw+s4IiIih+2A5cw5d2dNBBE5FH/9dCHL8wp549cDaVAv1us4IiIih01r2kit9e3STbzy3UpGHd2OYzqleR1HRESkWqicSa20bWcpt70zhw5NkvjT8G5exxEREak2B3O1pkjYePCDLHJ37GLs746mXly013FERESqjUbOpNb5dP56xs5cy3UndaJP64ZexxEREalWKmdSq+TuKObOsfPo1bIB1w3u5HUcERGRaqdyJrWGc467xs6jsKScpy7sQ2y0/vmKiEjk0W83qTXemZ7DZwty+dPwbnRqmuJ1HBERkZBQOZNaYc2WIh78IIujOjTmyqPbeR1HREQkZFTOJOyV+xy3vjOHKDOeuKAPUVFa1FxERCKXypmEvdHfrOCnFVu4/6wetGxYz+s4IiIiIaVyJmFt0YYd/G3iIoZlpHNu/5ZexxEREQk5lTMJWyVlPm4ZM5uUhBj+fE4vzHQ6U0REIl9Iy5mZDTezRWa21MzuqOL1NmY2xcxmmdlcMzstsD3WzF41s3lmtsDMtPh6HfTcF0vIWredx87pRVpyvNdxREREakTIypmZRQMvAKcCGcDFZpZRabd7gDHOuX7ARcA/AtvPB+Kdc72AI4DfmFm7UGWV8DNz9VZemLKU845oxbAezbyOIyIiUmNCOXI2AFjqnFvunCsB3gJGVNrHAfUDjxsA6ypsTzKzGKAeUAJsD2FWCSNFJWXcOmYOzRvU4/4zK/d5ERGRyBbKctYSWFPheU5gW0UPAJeZWQ7wMXB9YPu7QCGwHlgNPOGc21L5G5jZtWY23cym5+XlVXN88cpfPlnIik2FPHF+H1ISYr2OIyIiUqO8viDgYuAV51wr4DTgdTOLwj/qVg60ANoDt5pZh8pvds696JzLdM5lNmnSpCZzS4h8tTiP175fxdXHtueojo29jiMiIlLjQlnO1gKtKzxvFdhW0dXAGADn3PdAApAGXAJ86pwrdc7lAt8CmSHMKmFgW1Epf3x3Lp2aJnP7KV29jiMiIuKJUJazaUBnM2tvZnH4J/xPqLTPamAIgJl1x1/O8gLbBwe2JwGDgIUhzCph4P4J89lUsIunLuhLQmy013FEREQ8EbJy5pwrA64DJgIL8F+VmWVmD5nZWYHdbgWuMbM5wJvAKOecw3+VZ7KZZeEvef9xzs0NVVbx3kdz1zN+9jpuGNKZXq0aeB1HRETEM+bvQrVfZmammz59utcx5BDkbi9m2NNf0bZxEu/99ihior2eCikiIhJaZjbDOVfllC39FhRPOef403tz2VlSzpMX9FExExGROk+/CcVTb01bw5RFedx5ajc6Nkn2Oo6IiIjnVM7EM6s3F/Hwh9kc06kxvzqqnddxREREwoLKmXii3Oe49Z3ZREcZfzuvD1FRWtRcREQEIMbrAFI3/fvr5UxbuZWnLuxDi4b1vI4jIiISNjRyJjVuwfrtPDlpMaf2bMbZfSuv6CUiIlK3qZxJjdpVVs7Nb8+mfr1YHjm7J2Y6nSkiIlKRTmtKjXrmsyUs3LCDl36VSePkeK/jiIiIhB2NnEmNmbFqC/+cuowLM1tzcka613FERETCksqZ1IjCXWXcMmYOLRrW454zunsdR0REJGzptKbUiD9/vIDVW4p465pBpCTEeh1HREQkbGnkTEJuyqJc3vhxNdcc14GBHRp7HUdERCSsqZxJSOUXlfCnd+fSJT2ZW4Z28TqOiIhI2NNpTQmpe9/PYkthCaNHHUlCbLTXcURERMKeRs4kZCbMWccHc9Zx08md6dmygddxREREagWVMwmJDduKuXf8fPq1achvT+jodRwREZFaQ+VMqp1zjj++N5eSMh9PXtCXmGj9MxMREQmWfmtKtXvjx9V8tTiPu07rRvu0JK/jiIiI1CoqZ1KtVm4q5NGPFnBc5zQuG9TW6zgiIiK1jsqZVJtyn+OWMbOJjTYeP6+3FjUXERE5BLqVhlSbf05dxszV+TxzUV+aN6jndRwREZFaSSNnUi2y1m3j6c8Wc3rv5pzVp4XXcURERGotlTM5bLvKyrnl7Tk0TIzjkRE9dTpTRETkMOi0phy2JycvZtHGHfxn1JE0SorzOo6IiEitppEzOSzTVm7hxa+Wc/GANpzUranXcURERGo9lTM5ZAW7yrhlzGxaN0rkntO7ex1HREQkIui0phyyRz/KJmfrTsb85iiS4vVPSUREpDpo5EwOyRcLN/LmT2v4zfEdObJdqtdxREREIobKmRy0LYUl/PHdeXRrlsLNQzt7HUdERCSi6FyUHBTnHPeMn8e2nSW8dtUA4mOivY4kIiISUTRyJgdlwpx1fDxvAzcP7UJGi/pexxEREYk4KmcStPXbdnLv+Pkc0bYRvzm+o9dxREREIpLKmQTF53Pc/s5cynyOJy/oQ3SUVgEQEREJBZUzCcp/f1zFN0s3cffp3WnbOMnrOCIiIhFL5UwOaHleAX/+eAEndGnCJQPaeB1HREQkoqmcyX6Vlfu4Zcwc4mOiefy83lrUXEREJMR0Kw3Zr39OXcbsNfk8d3E/0usneB1HREQk4mnkTPZp/tptPP3ZEs7s04Iz+7TwOo6IiEidoHImVSouLefmt2fTODmOh0f08DqOiIhInaHTmlKlv09axJLcAl69agANE+O8jiMiIlJnaORMfuGH5Zt56ZsVXDaoDSd0aeJ1HBERkTpF5Ux+ZkdxKbe9M4c2qYncdVp3r+OIiIjUOSEtZ2Y23MwWmdlSM7ujitfbmNkUM5tlZnPN7LQKr/U2s+/NLMvM5pmZLhWsAQ9/mM26/J08eUFfEuN01ltERKSmhey3r5lFAy8AQ4EcYJqZTXDOZVfY7R5gjHPu/8wsA/gYaGdmMcB/gcudc3PMrDFQGqqs4jc5eyNjpufwh5M6ckTbRl7HERERqZNCOXI2AFjqnFvunCsB3gJGVNrHAfUDjxsA6wKPhwFznXNzAJxzm51z5SHMWudtLtjFnWPn0r15fW4c0sXrOCIiInVWKMtZS2BNhec5gW0VPQBcZmY5+EfNrg9s7wI4M5toZjPN7I8hzFnnOee4a9w8tu8s46kL+xAXo6mIIiIiXvH6t/DFwCvOuVbAacDrZhaF/3TrscClgb9HmtmQym82s2vNbLqZTc/Ly6vJ3BFl3Ky1TMzayK3DutCtWf0Dv0FERERCJpTlbC3QusLzVoFtFV0NjAFwzn0PJABp+EfZvnLObXLOFeEfVetf+Rs45150zmU65zKbNNEtHw7Fuvyd3P9+Fke2a8Svj+vgdRwREZE6L5TlbBrQ2czam1kccBEwodI+q4EhAGbWHX85ywMmAr3MLDFwccAJQDZSrXw+x23vzMHnHH8/vy/RUVrUXERExGshu1rTOVdmZtfhL1rRwGjnXJaZPQRMd85NAG4F/m1mN+O/OGCUc84BW83sSfwFzwEfO+c+ClXWuurV71fy3bLN/OWcXrRpnOh1HBERkUPjK4eSQijdCaWFUFIEpUWBbUX+7bsf7/m7yL9v6c69j3e/r35LuHSMZ4cT0htZOec+xn9KsuK2+yo8zgaO2cd7/4v/dhoSAktzC/jLJwsZ3K0pFx7Z+sBvEBEROVTOQVlxpRK0j2K0v5K1+3nFclVSBOW7Di6PRUFsEsQlQmwixCX5/46tB0lp0KhdSP5nCJbuMloHlZb7uGXMbBLjovnLub0w0+lMEZE6r7y0QjEq2sdIUxXFaM/fBxi1wh1cnph6e8tTbGLgcRIkN61QqOr9vFzt3qeq91XcFhMPYfy7T+WsDvrHlGXMzdnGPy7tT9MULbwgIlIr+HxQVsVI0y/K0iGezvMd5L3eo2IqjT4FSlBCfUhpdoCyVLFQVRi12vM4EaK8vqGEd1TO6pi5Ofk8+8USzu7bgtN6Nfc6johI5HAOykv2UYyCLVSVR60q7FO28yAD2c/LUMXH9Vr+vDxVLEY/K1T1KjyudBowOjYk/zOKylmdUlxazs1vz6ZJcjwPntXT6zgiIjWv4tynkoJKBajw56NMBzydV/Tz10sK4WAXs4mOq/q0XGIqxLasel7U/k7n/Wz0qV5Yn7qTfVM5q0Me/3QRy/IKef3qATRI1H/xiEgYKyupNKpU8PMSVGWJ2se2yqNQzhd8jionjgeKUVJaFcUoseqRpqpO58UmQrR+Dcsv6V9FHfHdsk2M/nYFVxzVluM664a9IlINfOVVF6CKI1JVjk5VGH0qKaz68cHOf6o8srT7cWLjX2772eNEiEuu4nFSrZg4LpFJ5awO2F5cyu3vzKVDWhJ3nNrd6zgiUpOc+/k8pv2OMgUzOlWhZJUVH1yW6PgKI0oVRpeSm/18pCkuqerHsYHyVPlxTL06PXlcIo/KWR3w0AfZrN+2k/d+dzT14qK9jiMiVdlzGq/w4EeZflGsKpWsg7mFgUVXKkCBIlWvETRo+fNRpsolK67S6bzK++oUnkhQ9P+UCDcxawPvzsjh+sGd6NemkddxRGq3PXchP8C8p/2OTlU+7RcoWb6yg8uyr1GmpCb7H2Xa7ym+JP8EdZ3GE/GUylkE21Swi7vGzqNny/pcP7iz13FEao/i7bDsC1g8EVZ/539eWnTwp/FiEqqeC5XSvIpRpqR9jzhVHp3SVXgiEU3lLEI557hz7Dx27CrjzQv6Ehej+Rgi+7VpKSyZCIs/hVXf+UeyEhpC++Mr3ZH8ACNPFR9HaRqBiBw8lbMI9e6MHCZnb+Se07vTJT3F6zgi4aesxD8qtniSv5BtWebf3qQ7HHUddDkFWg3QPCkRqXH6qROBcrYW8eAH2Qxsn8pVx7T3Oo5I+CjIg6WT/WVs6RdQssN/BWH742DQ76DzMGjU1uuUIlLHqZxFGJ/Pcds7c3DO8cT5fYiK0rwUqcOcgw1z946OrZ0BOP+cr57nQJfh0OEE/ylIEZEwoXIWYUZ/u4Iflm/h8XN70zo10es4IjWvpBCWTw3MH5sEO9YBBi37w0l3+U9XNuutCfUiErZUziLIko07eHziIk7uns75ma28jiNSc/JX+6+sXDwRVnwF5bsgLgU6nuQfHes81D+pX0SkFlA5ixCl5T5uHjOb5PgYHjunF6ZRAYlk5WWQMy0wOjYRcrP921M7wJFX+0fH2hwNMXHe5hQROQQqZxHiuS+WMn/tdv552RE0SYn3Oo5I9du5FZZ+7i9jSyf7n0fFQNujYdij/hGytE5epxQROWwqZxFg9pp8XpiylHP6t2R4z2ZexxGpHs5B3iL/RP4lk2D1D+DK/QtZdzkVugyDjoMhoYHXSUVEqpXKWS23s6ScW96eTXpKPPef2cPrOCKHp7QYVn2zd/5Y/ir/9ma94Nib/aNjLfvr5q4iEtFUzmq5v366kOWbCnnj1wNpUC/W6zgiB2/7ev/I2OKJsPxL/zqTMfWgw4lw7E3Q+RT/gtsiInWEylkt9s2STbzy3UquPKYdx3RK8zqOSHB8Plg/KzA69imsn+Pf3qA19L3YX8baH+dfP1JEpA5SOaultu0s5fZ359CxSRJ/Gt7N6zgi+7drByyb4i9kSyZBYS5YlH95pCH3+6+ubJqhe4+JiKByVms9OCGL3B27GPu7o0mI1fwbCUOblwVOV34KK78FX6l/8n6nk/1zxzqdDImpXqcUEQk7Kme10Cfz1jN21lpuHNKZPq0beh1HxK+8FFZ/v3cy/+Yl/u1pXf3rVnYZDq0HaiFxEZED0E/JWiZ3RzF3jZtH71YNuG6w7ukkHivc/POFxHdtg+g4aHcsDLjGv5B4anuvU4qI1CoqZ7WIc44735tHUUk5T17Qh9joKK8jSV3jHGzM8pexxRP9d+nHQXI6ZJwVWEj8RIhP9jqpiEitpXJWi4yZvobPF+Zy3xkZdGqa4nUcqStKimDl13sL2fa1/u0t+sOJdwQWEu8DUfqPBRGR6qByVkus2VLEQx9kc1SHxow6up3XcSTSbcupsJD4VCgrhrhk/6jYiXf6T1empHudUkQkIqmc1QLlPsetY+YQZcYTF/QhKkq3G5Bq5iuHnOl7FxLfON+/vVE7OGKUf3Ss7TEQo3VbRURCTeWsFnj5m+X8tHILT5zfh5YNdWNOqSY782HZ57B4kv+WFzu3gEVDm6Ng6MOBhcQ7695jIiI1TOUszC3asIMnJi5mWEY65/bXEjZyGJyDTUv2LiS+6jv/QuL1UqHzUP/oWMchUK+h10lFROo0lbMwVlLm4+a3Z1O/XgyPndML0wiGHKyyXbDq273zx7au8G9P7wnH3OgfHWuVqYXERUTCiMpZGHv28yVkr9/Oi5cfQeNkzfWRIO3YuPfO/Mu/hJICiEmA9ifA0df5165s2NrrlCIisg8qZ2Fq5uqt/OPLpZx/RCuG9WjmdRwJZz4fbJizdyHxdbP82+u3hN4XBBYSPx7iEr3NKSIiQVE5C0NFJWXc8vZsmjeox31nZngdR8LRrgL/qNju+WMFGwGDVkfC4Hv988fSe2oyv4hILaRyFoYe+3ghKzcX8eY1g0hJiPU6joSLLSsqLCT+DZSXQHx96DRk70LiSWlepxQRkcOkchZmpi7O4/UfVnH1se05qmNjr+OIl8rLYM2Pe+/Mv2mRf3vjzjDgWn8hazMIolXgRUQiicpZGNlWVMof351D56bJ3H5KV6/jiBeKtsDSzwILiX8GxdsgKhbaHQOZV/rvzN+4o9cpRUQkhFTOwsh9E+azuaCEl351JAmxurVBneAc5C6osJD4T+B8kNQUup0ZuPfYSRCvtVRFROoKlbMw8eHcdbw/ex23DO1Cr1YNvI4joVS60z9nbHch27bGv715Hzj+dn8ha95PC4mLiNRRKmdhIHd7MfeMn0+f1g35/Yk6ZRWRtq/beyPY5V9C2U6ITfIvJH787f7TlfWbe51SRETCgMqZx5xz/PG9uRSXlvPkBX2IidZoSUTwlcPamYGFxD+FDfP82xu2gf6XBxYSPxZiE7zNKSIiYSek5czMhgPPANHAS865v1R6vQ3wKtAwsM8dzrmPK72eDTzgnHsilFm98uZPa/hyUR4PntWDjk2SvY4jh6N4Gyz7Yu9C4kWbAguJD4KTH/RfXdmkq+49JiIi+xWycmZm0cALwFAgB5hmZhOcc9kVdrsHGOOc+z8zywA+BtpVeP1J4JNQZfTaqs2FPPJRNsd2SuPyQW29jiOHYtPSwI1gJ/oXEveVQb1G0Gn3QuKDITHV65QiIlKLhHLkbACw1Dm3HMDM3gJG4B8J280B9QOPGwDrdr9gZmcDK4DCEGb0TLnPceuYOURHGY+f15uoKI2m1AplJbD6u73zx7Ys829vmgFHX+9fKqnVkRCtGQMiInJoQvkbpCWwpsLzHGBgpX0eACaZ2fVAEnAygJklA3/CP+p2WwgzeubFr5YzfdVWnrqwDy0a1vM6juxLSZH/5q8b5vnvO7b0CyjZAdHx/vUqB/3OP0LWsI3XSUVEJEJ4/Z/3FwOvOOf+bmZHAa+bWU/8pe0p51yB7Wd+jpldC1wL0KZN7fnluGD9dp6cvIhTezbj7L4tvY4jAKXFsGkx5C2E3GzIXQh5C2DrKvwDvEBKc+h1rn/uWPvjIS7J08giIhKZQlnO1gKtKzxvFdhW0dXAcADn3PdmlgCk4R9hO8/MHsd/sYDPzIqdc89XfLNz7kXgRYDMzEwXioOobrvKyrn57dk0qBfHoyN7sb/yKSFQVgKbl/hv/Jq30P937gLYusJ/81eAqBho3Ama94U+l0DTbv7Tlo07aTK/iIiEXCjL2TSgs5m1x1/KLgIuqbTPamAI8IqZdQcSgDzn3HG7dzCzB4CCysWstnr6syUs3LCDl6/IJDUpzus4kau8FDYv849+7R4Fy10Im5eCK/fvY9GQ2gHSM6DnudC0u/9PakeI0WcjIiLeCFk5c86Vmdl1wET8t8kY7ZzLMrOHgOnOuQnArcC/zexm/OeORjnnasUI2KGYvnIL/5q6jIuObM2Q7ulex4kMvnLYssJ/KnL3SFjeQti0BHylgZ0MUttDk+7Q/Qz/3027Q1pniIn3NL6IiEhlFildKDMz002fPt3rGPtUuKuM0579mnKf49Objic53uvpfrWMzwf5K/2jX3uK2EL/PLHyXXv3a9jGfwqySTd/AWvSDdK6QFyiZ9FFREQqM7MZzrnMql5TQ6ghj368gNVbinjrmkEqZvvj8/nXmqw4CpabDXmL/Use7Va/lX8uWMcTAyNh3SCtK8TrRr4iIlK7qSXUgCmLcvnfj6u59vgODOzQ2Os44cE52L725/PBdv9dWuHWdinN/aNfmVcGRsMy/HfZT6i/768tIiJSi6mchdjWwhL+9O5cuqancMvQLl7HqXnOQcHGn9+eInehf0Rs1/a9+yU19Y9+9bvM//fu0bB6jbzLLiIi4gGVsxC79/35bC0q4T9XHklCbLTXcUKrIG9v+ao4Qb84f+8+9VL9o1+9L6gwL6w7JGlEUUREBFTOQmrCnHV8OHc9t5/SlR4tGngdp/oUbQnMB9tdxAKPizbv3Sehgb909Tj75xP0k5roXmEiIiL7oXIWIhu2FXPv+Pn0a9OQ3xzfwes4h2ZnfqWJ+YEbthbm7t0nLsV/+rHraXvvE9akO6Q0UwkTERE5BCpnIeCc44/vzaWkzMeTF/QlJjrK60j7t2sH5C365bywHev27hOb5J+I33no3lGwpt2hfkuVMBERkWqkchYC//1xNV8tzuPhET1onxZG6y+WFPpL2M/Wj1zov3XFbjEJ/vuCtT/+5xPzG7SBqDAvmSIiIhFA5ayardhUyJ8/WsDxXZpw2aC23oQo3em/OeueUbDAn/zV7FnEOzrOX8JaD4QjRu29YWujdhAV4RcuiIiIhDGVs2pUVu7j1jGziY02Hj+3d+gXNS/b5V+mqPK8sF8s4t0ZWvaHvpfuPR3ZqD1E6+MXEREJN/rtXI3+9dVyZq7O55mL+tKsQUL1feHdi3hXXj9y87KfL+LduCOk94Be5+29YWvjjhAdW31ZREREJKRUzqpJ1rptPP3ZYk7v3Zyz+rQ4tC9SXuYf9dp9GnL3xPzNS3+5iHfTDOh+VoX1I7WIt4iISCRQOasGxaXl3PL2HBomxvHIiJ4HPp3pK4etK395OnLTkkqLeLf1l6+uwyusH9kFYuuF9HhERETEOypn1eCpyYtZtHEH/7nySBolxe19Yfci3hVHwfIW/HIR7wat/aNfHU8KlLDu/ttWxIXRlZ4iIiJSI1TODtNPK7bw4tfL+F2/BE6KmgvfVpwXtqjSIt4t/KNfmVftvU2FFvEWERGRClTODoZzsGPDnlGw0g1ZJM77iXnxOSQvKIIFgf12L+Ld//IK60d2g3oNvUwvIiIitYDKWbB85fD3bj9bumhXdAMKylpQlHEOyR377T0lmZjqYVARERGpzVTOghUV7T8dmZgKTbvzVX4av3p7Bb89oSODTu3mdToRERGJECpnB+OkOwHYUljCLW98RbdmKdw8tLPHoURERCSSqJwdJOccd4+bx7adJbx+9QDiY7TUkYiIiFQfrWR9kN6fvY5P5m/glqFd6d5cV1mKiIhI9VI5Owjrt+3k3vfnc0TbRlx7fAev44iIiEgEUjkLks/nuP2duZT7HE9e0IfoqBAvai4iIiJ1kspZkApLyjCDu0/vTtvGunO/iIiIhIYuCAhSSkIsr101wOsYIiIiEuFUzg7CARc0FxERETlMOq0pIiIiEkZUzkRERETCiMqZiIiISBhRORMREREJIypnIiIiImFE5UxEREQkjKiciYiIiIQRlTMRERGRMKJyJiIiIhJGVM5EREREwojKmYiIiEgYUTkTERERCSMqZyIiIiJhROVMREREJIyonImIiIiEEZUzERERkTCiciYiIiISRsw553WGamFmecCqGvhWacCmGvg+4aguHzvU7ePXsddddfn46/KxQ90+/po49rbOuSZVvRAx5aymmNl051ym1zm8UJePHer28evY6+axQ90+/rp87FC3j9/rY9dpTREREZEwonImIiIiEkZUzg7ei14H8FBdPnao28evY6+76vLx1+Vjh7p9/J4eu+aciYiIiIQRjZyJiIiIhBGVs30ws+FmtsjMlprZHVW8Hm9mbwde/9HM2nkQMySCOPZRZpZnZrMDf37tRc5QMLPRZpZrZvP38bqZ2bOB/23mmln/ms4YKkEc+4lmtq3C535fTWcMFTNrbWZTzCzbzLLM7MYq9onkzz6Y44/Iz9/MEszsJzObEzj2B6vYJyJ/3gd57BH78343M4s2s1lm9mEVr3nz2Tvn9KfSHyAaWAZ0AOKAOUBGpX1+D/wz8Pgi4G2vc9fgsY8Cnvc6a4iO/3igPzB/H6+fBnwCGDAI+NHrzDV47CcCH3qdM0TH3hzoH3icAiyu4t99JH/2wRx/RH7+gc8zOfA4FvgRGFRpn0j9eR/MsUfsz/sKx3gL8L+q/n179dlr5KxqA4ClzrnlzrkS4C1gRKV9RgCvBh6/CwwxM6vBjKESzLFHLOfcV8CW/ewyAnjN+f0ANDSz5jWTLrSCOPaI5Zxb75ybGXi8A1gAtKy0WyR/9sEcf0QKfJ4FgaexgT+VJ2NH5M/7II89oplZK+B04KV97OLJZ69yVrWWwJoKz3P45Q+qPfs458qAbUDjGkkXWsEcO8C5gVM775pZ65qJFhaC/d8nUh0VOAXyiZn18DpMKAROW/TDP4pQUZ347Pdz/BChn3/gtNZsIBeY7Jzb52cfYT/vgzl2iOyf908DfwR8+3jdk89e5UwOxQdAO+dcb2Aye/+rQiLbTPzLjfQBngPGexun+plZMvAecJNzbrvXeWraAY4/Yj9/51y5c64v0AoYYGY9PY5UY4I49oj9eW9mZwC5zrkZXmepTOWsamuBiv910Cqwrcp9zCwGaABsrpF0oXXAY3fObXbO7Qo8fQk4ooayhYNg/m1EJOfc9t2nQJxzHwOxZpbmcaxqY2ax+IvJG865sVXsEtGf/YGOP9I/fwDnXD4wBRhe6aVI/Xm/x76OPcJ/3h8DnGVmK/FP4RlsZv+ttI8nn73KWdWmAZ3NrL2ZxeGfBDih0j4TgCsCj88DvnCBGYO13AGPvdI8m7Pwz0+pKyYAvwpcuTcI2OacW+91qJpgZs12z7UwswH4f35ExC+owHG9DCxwzj25j90i9rMP5vgj9fM3syZm1jDwuB4wFFhYabeI/HkfzLFH8s9759ydzrlWzrl2+H/XfeGcu6zSbp589jGh/ga1kXOuzMyuAybiv3pxtHMuy8weAqY75ybg/0H2upktxT+J+iLvElefII/9BjM7CyjDf+yjPAtczczsTfxXpaWZWQ5wP/5Jsjjn/gl8jP+qvaVAEXClN0mrXxDHfh7wOzMrA3YCF0XCL6iAY4DLgXmB+TcAdwFtIPI/e4I7/kj9/JsDr5pZNP7COcY592Fd+HlPcMcesT/v9yUcPnutECAiIiISRnRaU0RERCSMqJyJiIiIhBGVMxEREZEwonImIiIiEkZUzkRERETCiMqZiMhhMrMTzexDr3OISGRQORMREREJIypnIlJnmNllZvaTmc02s38FFn0uMLOnzCzLzD43syaBffua2Q+BBZ/HmVmjwPZOZvZZYAHwmWbWMfDlkwMLQy80szd2301fRORgqZyJSJ1gZt2BC4FjAgs9lwOXAkn47wbeA5iKf2UEgNeAPwUWfJ5XYfsbwAuBBcCPBnYv4dQPuAnIADrgv+u+iMhB0/JNIlJXDMG/aPO0wKBWPSAX8AFvB/b5LzDWzBoADZ1zUwPbXwXeMbMUoKVzbhyAc64YIPD1fnLO5QSezwbaAd+E/KhEJOKonIlIXWHAq865O3+20ezeSvsd6pp2uyo8Lkc/X0XkEOm0pojUFZ8D55lZUwAzSzWztvh/Dp4X2OcS4Bvn3DZgq5kdF9h+OTDVObcDyDGzswNfI97MEmvyIEQk8um/7ESkTnDOZZvZPcAkM4sCSoE/AIXAgMBrufjnpQFcAfwzUL6WA1cGtl8O/MvMHgp8jfNr8DBEpA4w5w51BF9EpPYzswLnXLLXOUREdtNpTREREZEwopEzERERkTCikTMRERGRMKJyJiIiIhJGVM5EREREwojKmYiIiEgYUTkTERERCSMqZyIiIiJh5P8BDYVBg6OK/noAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the accuracy bert_multilingual and kobert\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(epochs), train_accuracy_kobert_per_epoch, label='kobert')\n",
    "plt.plot(range(epochs), validation_accuracy_bert_multilingual_cased_per_epoch, label='bert_multilingual')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.10 (NGC 21.11/Python 3.8 Conda) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d29624fa02f72a2f2eb64b5fa4dfbc751609e2b6c88be691c0db207c64cc14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
