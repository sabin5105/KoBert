# KoBert

KoBert from SKTbrain and Bert multi lingual comparison

<hr>

You can find the main task and notebook in the notebook/main.ipynb

# Korean emotion analysis with BERT based model

## 1. bert-base-multilingual-cased
    * Bert tokenzier from transformers & Bert for sequence classification
    * 도서 "딥 러닝을 통한 자연어 처리 입문" 참고

## 2. KoBERT
    * SKTBrain 팀이 개발한 Bert 모델 기반 한국어 성능 향상
    * Model 내부 및 예측 흐름 확인
    
## 3. Conclusion
    * 임의의 input 문장이 들어왔을 때 긍정/부정 판별
    * 두 개의 모델 Accuracy 비교
    * 학습 내용 시각화

<img width="364" alt="image" src="https://user-images.githubusercontent.com/50198431/180638607-28cba23c-479d-4afc-b64b-503869220fb5.png">
<img width="441" alt="image" src="https://user-images.githubusercontent.com/50198431/180638614-26d48590-642d-4028-890a-1d011954d00d.png">
<img width="605" alt="image" src="https://user-images.githubusercontent.com/50198431/180638622-7cd265da-a394-4394-9ce5-4657945afa3c.png">
<img width="612" alt="image" src="https://user-images.githubusercontent.com/50198431/180638654-1400d23e-d497-4d9d-aae9-69cb6392fdd1.png">

<hr>

* The basic code of main notebook is came from the SKTbrain github (https://github.com/SKTBrain/KoBERT)

* Another reference is the book called "딥 러닝을 이용한 자연어 처리 입문 - 유원준 외 1명" (https://wikidocs.net/book/2155)
